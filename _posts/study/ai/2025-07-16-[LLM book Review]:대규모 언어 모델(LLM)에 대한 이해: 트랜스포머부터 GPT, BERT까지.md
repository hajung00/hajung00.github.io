---
title: 대규모 언어 모델(LLM)에 대한 이해
author: cotes
date: 2025-07-16 01:33:00 +0800
categories: [Study, AI]
tags: [AI]
---

최근 몇 년간 인공지능 분야에서 가장 뜨거운 키워드 중 하나는 바로 **대규모 언어 모델**일 것입니다. ChatGPT나 Gemini와 같은 LLM은 이미 우리 삶의 다양한 영역에 깊숙이 파고들어 놀라운 능력을 보여주고 있습니다. 이 글에서는 최근 접한 책의 내용을 바탕으로 LLM의 핵심 개념, 특히 트랜스포머 아키텍처와 그 파생 모델들의 작동 원리, 그리고 학습 방식에 대한 저의 이해와 새로운 깨달음을 공유하고자 합니다.

<br/>

> ## 1. LLM이란 무엇인가?
LLM은 사람과 같은 텍스트를 이해하고, 생성하며, 응답하도록 설계된 인공 신경망입니다. 수십억 개에 달하는 방대한 매개변수를 가지며, 인터넷에서 공개적으로 사용 가능한 대규모 텍스트 데이터에 대해 훈련됩니다. 텍스트를 생성하는 능력 때문에 '생성형 인공지능(GenAI)'의 핵심 기술로 불리기도 합니다. 기존 NLP 모델이 특정 작업에 맞춰 설계된 것과 달리, 현재의 LLM은 광범위한 NLP 작업에서 뛰어난 다재다능함을 보여줍니다.

<br/>

---

<br/>

> ## 2. 기존 NLP의 한계와 트랜스포머의 등장
과거의 자연어 처리(NLP) 모델들은 주로 텍스트 분류, 언어 번역과 같이 특정 작업에 맞게 설계되었습니다. 이러한 모델들은 좁은 응용 분야에서는 뛰어났지만, 인간 언어의 깊은 맥락적 정보나 미묘한 뉘앙스를 포착하는 데 한계가 있었고, 각 작업마다 별도의 모델을 만들고 훈련해야 하는 비효율성도 존재했습니다.

<br/>

2017년, 구글이 발표한 "Attention Is All You Need" 논문에서 소개된 트랜스포머(Transformer) 아키텍처는 이러한 한계를 극복하며 NLP 분야에 혁명적인 변화를 가져왔습니다. 트랜스포머의 핵심인 '셀프-어텐션(Self-Attention)' 메커니즘은 모델이 시퀀스 내의 모든 단어들 간의 관계를 동시에 파악하고, 멀리 떨어진 단어 간의 의존성까지 효율적으로 처리할 수 있게 했습니다. 이로 인해 LLM은 기존 NLP 작업의 성능을 비약적으로 향상시켰을 뿐만 아니라, 다음과 같은 광범위하고 복잡한 언어 작업을 수행할 수 있는 기반을 마련했습니다.

<br/>

- 새로운 텍스트 생성: 소설, 기사, 시, 컴퓨터 코드 등 창의적이고 일관성 있는 텍스트를 생성합니다.

- 챗봇 및 가상 비서 구현: 인간과 자연스러운 대화를 나누며 다양한 질문에 답변합니다.

- 텍스트 요약: 긴 문서를 핵심 내용으로 간결하게 요약합니다.

- 제로샷(Zero-shot) 학습: 사전 특정 예시 없이 완전히 새로운 작업을 수행합니다.

- 퓨샷(Few-shot) 학습: 몇 가지 예시만으로 새로운 작업을 학습하고 수행합니다.

- 전문 분야 지식 검색: 의학, 법률 등 특정 전문 분야의 방대한 텍스트에서 효과적으로 지식을 검색하고 질문에 답변합니다.

<br/>

---

<br/>

> ## 3. 트랜스포머의 원조와 BERT, GPT의 훈련 방식 및 역할
원본 트랜스포머는 기계 번역을 위해 개발되었으며, 입력 언어를 인코딩하는 '인코더'와 이를 바탕으로 대상 언어를 생성하는 '디코더'의 조합으로 구성됩니다. 그러나 이 아키텍처는 이후 다양한 형태로 분화되며 각기 다른 강점을 가진 LLM으로 발전했습니다.

<br/>

### 3.1. 인코더 모듈 기반의 BERT

- **아키텍처**: BERT(Bidirectional Encoder Representations from Transformers)는 원본 트랜스포머의 인코더 부분에 중점을 둔 아키텍처입니다.

- **훈련 방식**: BERT의 핵심 훈련 방식은 **마스킹된 단어 예측**입니다. 이는 문장 내의 특정 단어들을 임의로 가린 후, 모델이 문장의 양쪽 문맥(즉, 가려진 단어의 앞과 뒤 모두)을 모두 보고 가려진 단어가 무엇일지 예측하도록 훈련하는 방식입니다.

- **수행 가능한 작업**: 이러한 양방향 문맥 이해 능력 덕분에 BERT는 **텍스트 분류, 감성 예측, 문서 분류, 개체명 인식, 질문 응답**과 같이 언어를 '이해'하고 분석하는 작업에 특히 강력합니다.

<br/>

 ### 3.2. 디코더 모듈 기반의 GPT

- **아키텍처**: GPT(Generative Pre-trained Transformer)는 원본 트랜스포머의 디코더 부분에 중점을 둔 아키텍처입니다. GPT, 그리고 Llama와 같은 후속 모델들도 이 디코더 전용 아키텍처를 따릅니다.

- **훈련 방식**: GPT의 핵심 훈련 방식은 **다음 단어 예측**입니다. 모델은 주어진 텍스트 시퀀스 다음에 올 단어가 무엇일지 예측하도록 학습합니다. 이 과정에서 모델은 오직 이전 단어들만을 참조하며(단방향 어텐션), 예측된 단어를 다시 입력으로 사용하여 다음 단어를 생성하는 '자기회귀(auto-regressive)' 방식으로 작동합니다.

- **수행 가능한 작업**: 이러한 생성 방식 덕분에 GPT는 새로운 텍스트 생성(이야기, 에세이, 시), 텍스트 완성, 코드 생성, 기계 번역, 요약 등 언어를 '생성'하는 작업에 매우 뛰어납니다.

<br/>

---

<br/>

> ## 4. LLM 학습의 핵심: 사전 훈련과 미세 조정
LLM 구축은 크게 두 단계로 이루어지며, 이는 대규모 모델의 효율적인 개발 및 활용을 가능하게 합니다.

<br/>

### 4.1. 사전 훈련 (Pre-training)

- **레이블 없음**: 사전 훈련 단계에서는 레이블이 없는 방대한 양의 '원시(raw)' 텍스트 코퍼스를 사용합니다. 즉, 데이터에 특정 작업에 대한 정답(예: 스팸/비-스팸 레이블, 번역문)이 명시적으로 주어지지 않습니다.

- **다음 단어 예측 학습**: 모델은 코퍼스 내에서 스스로 레이블을 생성하는 '자기 지도 학습' 방식, 즉 **다음 단어 예측**을 통해 학습합니다. 텍스트 시퀀스의 일부를 입력으로, 그 시퀀스 바로 다음에 오는 단어를 정답으로 간주하여 언어의 통계적 패턴, 문법, 의미, 그리고 세상에 대한 일반적인 지식까지 학습합니다. 이 과정을 통해 LLM은 범용적인 '기초 모델(Foundation Model)'이 됩니다. GPT-3의 경우 사전 훈련에만 약 460만 달러의 비용이 들 정도로 막대한 자원과 시간이 소요됩니다.

<br/>

### 4.2. 미세 조정 (Fine-tuning)

- **레이블 사용**: 사전 훈련된 기초 모델은 이어서 특정 작업에 대한 '레이블이 지정된(labeled)' 데이터셋으로 추가 훈련됩니다.

- **다양한 미세 조정**

  - 명령어 미세 조정: 질문과 답변 쌍과 같은 형식의 데이터를 사용하여 모델이 사용자 지시(명령어)에 따라 응답하도록 학습합니다 (예: 챗봇, 개인 비서).

  - 분류 미세 조정: 텍스트와 해당 텍스트의 분류 클래스 레이블(예: 스팸 이메일/일반 이메일) 쌍을 사용하여 모델이 텍스트를 특정 범주로 분류하도록 학습합니다.

  - 미세 조정은 사전 훈련된 모델의 광범위한 지식을 특정 작업에 '맞춤화'하여 성능을 극대화하고, 훨씬 적은 데이터와 컴퓨팅 자원으로도 효율적인 학습이 가능하게 합니다. 이는 이미 존재하는 사전 훈련된 모델 가중치를 재사용하여 비용이 많이 드는 사전 훈련 단계를 건너뛸 수 있게 해줍니다.

<br/>

---

<br/>

> ## 5. 새롭게 알게 된 점 및 핵심 깨달음

### 5.1. 왜 생성형 LLM은 디코더로만 이루어져 있는가?
생성형 LLM의 핵심 목표는 새로운 텍스트를 "생성"하는 것입니다. 디코더는 이러한 생성 작업에 최적화된 특성을 가집니다.

- **자기회귀적(Auto-regressive) 특성**: 디코더는 현재까지 생성된 텍스트를 기반으로 다음 단어를 예측하고 생성하는 '자기회귀' 방식을 사용합니다. 이는 마치 사람이 글을 이어 쓰듯이, 이전에 쓴 내용에 기초하여 다음 내용을 만들어내는 과정과 같습니다. 인코더-디코더 모델이 특정 입력을 받아 새로운 출력을 '변환'하는 데 중점을 둔다면, 디코더 전용 모델은 '이어 붙여서' '생성'하는 데 특화되어 있습니다.

- **단방향 어텐션 (Masked Self-Attention)**: 디코더는 텍스트를 생성할 때 현재 예측해야 할 단어의 "미래" 단어들을 보지 못하도록 설계되어 있습니다(마스킹된 셀프-어텐션). 이는 모델이 실제 창의적인 텍스트를 '생성'하게 하여, 단순히 데이터를 복사하는 것을 방지하고 언어의 통계적 패턴을 기반으로 새로운 조합을 만들어내도록 유도합니다.

<br/>


### 5.2. 레이블 없는 대규모 코퍼스로 어떻게 다음 단어를 예측하도록 학습하는가?
이것은 LLM 학습의 핵심이자 '자기 지도 학습(Self-supervised Learning)'의 정수입니다.

- **데이터 자체를 레이블로 활용**: LLM은 방대한 양의 '원시(raw)' 텍스트 데이터(즉, 인간이 수동으로 분류하거나 번역하지 않은 순수한 텍스트)를 사용합니다. 이 텍스트 내에서 모델은 "이전 단어들"을 입력으로 삼고, 그 "바로 다음 단어"를 정답(레이블)으로 간주하여 학습합니다.

- **슬라이딩 윈도우 방식**: 모델은 텍스트 코퍼스를 '슬라이딩 윈도우' 방식으로 이동하며 수십억, 수조 개의 '입력 시퀀스 → 다음 단어' 쌍을 생성합니다. 예를 들어, "하늘은 파랗고 구름은 하얗다."라는 문장이 있다면, 모델은 "하늘은" 다음 "파랗고"를 예측하고, "하늘은 파랗고" 다음 "구름은"을 예측하는 식의 반복 학습을 수행합니다.

- **패턴 학습 및 지식 습득**: 이러한 반복적인 다음 단어 예측 학습을 통해 모델은 단순히 단어의 배열을 외우는 것을 넘어섭니다. 언어의 문법 구조, 단어 간의 의미적 관계, 문맥적 흐름, 심지어 코퍼스에 담긴 방대한 일반 상식 및 세계 지식까지 점진적으로 학습하게 됩니다. 이러한 학습 과정에서 모델은 번역이나 요약과 같이 명시적으로 훈련되지 않은 작업도 수행할 수 있는 '돌발 행동(emergent behavior)' 능력을 갖추게 되는 것입니다.

<br/>

결론적으로, 이 책을 통해 LLM, 특히 GPT와 Llama와 같은 생성형 모델이 인코더 없는 디코더 아키텍처를 통해 어떻게 언어를 이해하고 생성하는지에 대한 메커니즘을 깊이 있게 이해할 수 있었습니다. '다음 단어 예측'이라는 단순한 자기 지도 학습 목표가 어떻게 복잡하고 지능적인 언어 능력을 이끌어내는가에 대한 설명은 인공지능의 발전 방식에 대한 큰 통찰력을 제공했습니다.

